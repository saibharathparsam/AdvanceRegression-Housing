{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2171882",
   "metadata": {},
   "source": [
    "## Case Study\n",
    "A US-based housing company named Surprise Housing has decided to enter the Australian market. The company uses data analytics to purchase houses at a price below their actual values and flip them on at a higher price. For the same purpose, the company has collected a data set from the sale of houses in Australia. The data is provided in the CSV file below.\n",
    "\n",
    "The company is looking at prospective properties to buy to enter the market. You are required to build a regression model using regularisation in order to predict the actual value of the prospective properties and decide whether to invest in them or not.\n",
    "\n",
    " \n",
    "#### Intent\n",
    "The company wants to know:\n",
    "\n",
    "- Which variables are significant in predicting the price of a house, and\n",
    "- How well those variables describe the price of a house.\n",
    "- Also, determine the optimal value of lambda for ridge and lasso regression.\n",
    "\n",
    "#### Business Goal \n",
    "\n",
    "You are required to model the price of houses with the available independent variables. This model will then be used by the management to understand how exactly the prices vary with the variables. They can accordingly manipulate the strategy of the firm and concentrate on areas that will yield high returns. Further, the model will be a good way for management to understand the pricing dynamics of a new market."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b78876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data \n",
    "\n",
    "df = pd.read_csv(\"./train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f64f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0010a04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff6aa09",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f5ace1",
   "metadata": {},
   "source": [
    "## Data cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8de8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check null percentage\n",
    "# print(df.isnull().sum())\n",
    "def check_null(df):\n",
    "    df_null = df.isnull().sum()\n",
    "    print(df_null[df_null> 0])\n",
    "    df_null = round(df_null[df_null> 0]/len(df.index), 9)\n",
    "    df_null = df_null.sort_values()\n",
    "    print(df_null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff982b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "nd = check_null(df)\n",
    "nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed04c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Few categorical columns having missing values have business importance like House without Pool has PoolQC as null. Replace those values with a valid category value\n",
    "\n",
    "\n",
    "df[\"BsmtQual\"].fillna(\"NoBasement\", inplace=True)\n",
    "df[\"BsmtCond\"].fillna(\"NoBasement\", inplace=True)\n",
    "df[\"BsmtFinType1\"].fillna(\"NoBasement\", inplace=True)\n",
    "df[\"BsmtExposure\"].fillna(\"NoBasement\", inplace=True)\n",
    "df[\"BsmtFinType2\"].fillna(\"NoBasement\", inplace=True)\n",
    "\n",
    "df[\"GarageCond\"].fillna(\"NoGarage\", inplace=True)\n",
    "df[\"GarageQual\"].fillna(\"NoGarage\", inplace=True)\n",
    "df[\"GarageFinish\"].fillna(\"NoGarage\", inplace=True)\n",
    "df[\"GarageType\"].fillna(\"NoGarage\", inplace=True)\n",
    "\n",
    "df[\"FireplaceQu\"].fillna(\"NoFireplace\", inplace=True)\n",
    "df[\"Fence\"].fillna(\"NoFence\", inplace=True)\n",
    "df[\"Alley\"].fillna(\"NoAlleyAccess\", inplace=True)\n",
    "df[\"MiscFeature\"].fillna(\"None\", inplace=True)\n",
    "df[\"PoolQC\"].fillna(\"NoPool\", inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9a801b",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_null(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d1d97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Electrical.mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5fb3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MasVnrType'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19c8367",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MasVnrType'].fillna(\"None\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcce6599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data  Imputation\n",
    "df['LotFrontage'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fa1eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MasVnrArea'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e383077b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['GarageYrBlt'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3788017",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['LotFrontage'] = df[\"LotFrontage\"].transform(lambda x: x.fillna(df['LotFrontage'].median()))\n",
    "df[\"GarageYrBlt\"].fillna(df[\"GarageYrBlt\"].median(), inplace=True)\n",
    "df[\"MasVnrArea\"].fillna(df[\"MasVnrArea\"].median(), inplace=True)\n",
    "df['Electrical'].fillna('SBrkr', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89c2ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identify the record where Basement value is specified where it is not having a basement for remaining basement columns\n",
    "df1=df[(df.BsmtExposure=='NoBasement')]\n",
    "df2=df[(df.BsmtFinType1=='NoBasement') & (df.BsmtCond=='NoBasement') & (df.BsmtQual=='NoBasement')]\n",
    "df1[~df1.isin(df2)].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe9c349",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identify the record where Basement value is specified where it is not having a basement for remaining basement columns\n",
    "df1=df[(df.BsmtFinType2=='NoBasement')]\n",
    "df2=df[(df.BsmtFinType1=='NoBasement') & (df.BsmtCond=='NoBasement') & (df.BsmtQual=='NoBasement')]\n",
    "df1[~df1.isin(df2)].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ab5ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#deleting the records that are identified above and having bad data\n",
    "df=df[(df.Id!=333.0) & (df.Id!=949.0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db546f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_null(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5474332",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna( inplace=True)\n",
    "check_null(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a7c46f",
   "metadata": {},
   "source": [
    "### drop id columns as it has no business significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b7c48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=\"Id\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b58ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ce2f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bbea9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can see that all nulls has been handeled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f87e67",
   "metadata": {},
   "source": [
    "# EDA\n",
    "Performing EDA to understand more about columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c38327c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def histogram(v):\n",
    "    sns.distplot(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d4a138",
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram(df.GarageYrBlt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9814fad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the distribution plot for Garage built year. Based on this we see that 2000+ is the year where mostly built. \n",
    "#We can say any house built after 2000 as new built where as other as old\n",
    "\n",
    "def EncodeGarageType(x):\n",
    "    if x<2000:\n",
    "        return 1\n",
    "    if x>=2000:\n",
    "        return 2\n",
    "    if str(x)=='nan':\n",
    "        return 0\n",
    "df['GarageYrBlt']=df.GarageYrBlt.apply(EncodeGarageType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce02fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "histogram(df['SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c8b6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Skewness =  %f\" % df['SalePrice'].skew())\n",
    "print(\"Kurtosis = %f\" % df['SalePrice'].kurt())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd694061",
   "metadata": {},
   "source": [
    "### Observations\n",
    "\n",
    "From the above distribution of saleprice the SalePrice is positively skewed  and to make it normally distributed we need to transform it to log scale\n",
    "Since Kurtosis is greater than 3 , SalePrice contains outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a462a5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def desc(x):\n",
    "    print(df[x].describe(percentiles=[.1,.25,.5,.75,.90,.95,0.97,0.98,0.99]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bba5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "desc('SalePrice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b412970f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since saleprice above 95% is highly skewed let's remove those out liers\n",
    "quantile = df['SalePrice'].quantile(0.95)\n",
    "df = df[df[\"SalePrice\"] < quantile] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec3182b",
   "metadata": {},
   "outputs": [],
   "source": [
    "desc('SalePrice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3fc249",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(percentiles=[.1,.25,.5,.75,.90,.95,0.97,0.98,0.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5401f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looks like LotArea has high skew between 99th and 100th percentile lets remove it\n",
    "quantile = df['LotArea'].quantile(0.99)\n",
    "df = df[df[\"LotArea\"] < quantile] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f583946",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MiscVal there is a very high skew between 99th and 100 percentile lets remove those rows\n",
    "quantile = df['MiscVal'].quantile(0.99)\n",
    "df = df[df[\"MiscVal\"] < quantile] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad831b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MasVnrArea is nearly 3 time between 99th and 100th percentile lets remove those rows\n",
    "quantile = df['MasVnrArea'].quantile(0.99)\n",
    "df = df[df[\"MasVnrArea\"] < quantile]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3b597c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BsmtFinSF2 is twice beween 99th and 100 percentile lets remove it\n",
    "quantile = df['BsmtFinSF2'].quantile(0.99)\n",
    "df = df[df[\"BsmtFinSF2\"] < quantile]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b33f6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (40, 20))\n",
    "sns.heatmap(df.corr(), annot=True, cmap=\"jet\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb50d4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#there is 88% correlation between GarageCars and GarageArea so dropping cars\n",
    "df.drop(columns=\"GarageCars\", inplace=True)\n",
    "\n",
    "#there is 76% corelation between TotalBsmtSF and 1stFlrSF dropping one\n",
    "df.drop(columns=\"TotalBsmtSF\", inplace=True)\n",
    "\n",
    "#there is 83% corelation between TotRmsAbvGrd  and GrLivArea  dropping one\n",
    "df.drop(columns=\"TotRmsAbvGrd\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510cd339",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_types = df.dtypes\n",
    "numeric_cols = list(data_types[(data_types == 'int64') | (data_types == float)].index)\n",
    "categorical_cols = list(data_types[data_types == object].index)\n",
    "print(len(numeric_cols))\n",
    "print(len(categorical_cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420a7532",
   "metadata": {},
   "source": [
    "#### Observations\n",
    "There are few variables like OverallQual, YearBuilt , YearRemodAdd, TotalBsmtSF, 1stFlrSF, GrLivArea, FullBath, GarageCars, GarageArea and MoSold are highly positvely correlated to SalePrice.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614b7f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'SalePrice', 'OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', 'FullBath', 'YearBuilt'\n",
    "#Lets plot the box plot to see the values\n",
    "#set the number of columns to 2\n",
    "numcol=2\n",
    "#get the number of rows to plot\n",
    "rows=len(numeric_cols)//numcol+1\n",
    "#set the fig size\n",
    "plt.figure(figsize=(17,32))\n",
    "#for each numeric column plot\n",
    "for index,column in enumerate(numeric_cols):\n",
    "    #choose the plot\n",
    "    plt.subplot(rows,numcol,index+1)\n",
    "    #plot the box plot\n",
    "    sns.boxplot(x=column, data=df, color='red')\n",
    "plt.tight_layout()   \n",
    "plt.show()  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b25ced3",
   "metadata": {},
   "source": [
    "#### Observations\n",
    "We can see that data is nearly good but it is likely that we have some outliers. We cannot remove these as it will cause signifincat data loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b66611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the numerical values using pairplots\n",
    "\n",
    "plt.figure(figsize=(10,15))\n",
    "sns.pairplot(df, x_vars=['MSSubClass', 'LotFrontage', 'LotArea'], y_vars='SalePrice',kind='scatter',diag_kind=None)\n",
    "sns.pairplot(df, x_vars=['OverallQual', 'OverallCond', 'YearBuilt'], y_vars='SalePrice',kind='scatter',diag_kind=None)\n",
    "sns.pairplot(df, x_vars=['YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1'], y_vars='SalePrice',kind='scatter',diag_kind=None)\n",
    "sns.pairplot(df, x_vars=['BsmtFinSF2','BsmtUnfSF', '1stFlrSF'], y_vars='SalePrice',kind='scatter',diag_kind=None)\n",
    "sns.pairplot(df, x_vars=['BsmtFullBath', 'FullBath'], y_vars='SalePrice',kind='scatter',diag_kind=None)\n",
    "sns.pairplot(df, x_vars=['HalfBath', 'BedroomAbvGr', 'YrSold'], y_vars='SalePrice',kind='scatter',diag_kind=None)\n",
    "sns.pairplot(df, x_vars=['Fireplaces', 'GarageYrBlt', 'GarageArea'], y_vars='SalePrice',kind='scatter',diag_kind=None)\n",
    "sns.pairplot(df, x_vars=['WoodDeckSF','OpenPorchSF', 'EnclosedPorch'], y_vars='SalePrice',kind='scatter',diag_kind=None)\n",
    "sns.pairplot(df, x_vars=['2ndFlrSF', 'GrLivArea'], y_vars='SalePrice',kind='scatter',diag_kind=None)\n",
    "sns.pairplot(df, x_vars=[ 'FullBath'], y_vars='SalePrice',kind='scatter',diag_kind=None)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86e9956",
   "metadata": {},
   "source": [
    "#### Observations\n",
    "based on below plots we see some trend or linear pattern observed between SalesPrice and LotArea,YearBuilt, YearRemodAdd, BsmtFinSF1, 1stFlrSF, GarageArea, 2ndFlrSF,  GrLivArea, TotalBsmtSF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fcd11b",
   "metadata": {},
   "source": [
    "###  Data Preparation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512be12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### As we see earlier as part of EDA the SalePrice is not normally distributed and positively skewed let's transform the saleprice to log scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60022544",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"TransformedPrice\"] = np.log(df[\"SalePrice\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760b6a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df[\"TransformedPrice\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7112fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating dummy columns for all string type categorical columsn\n",
    "columns=df.select_dtypes(include=['object']).columns\n",
    "for column in columns:\n",
    "    df_d = pd.get_dummies(df[column], prefix=column, drop_first = True)\n",
    "    df = pd.concat([df, df_d], axis = 1)\n",
    "    df.drop(columns=[column],axis=1, inplace=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d6ceb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3630519",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"SalePrice\"], axis=1)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6f9418",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9146ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, train_size = 0.7, test_size = 0.3, random_state = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f78fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb43d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying scaling on training set\n",
    "num_vars = df_train.select_dtypes(include=np.number).columns\n",
    "df_train[num_vars] = scaler.fit_transform(df_train[num_vars])\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7479ab39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying the scaling learnt on Test set\n",
    "df_test[num_vars] = scaler.transform(df_test[num_vars])\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8603f972",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating X and Y sets for training and testing\n",
    "y_train = df_train.pop('TransformedPrice')\n",
    "X_train = df_train\n",
    "\n",
    "y_test = df_test.pop('TransformedPrice')\n",
    "X_test = df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402fd3e8",
   "metadata": {},
   "source": [
    "### Model Building\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b30915d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of alphas to tune\n",
    "params = {'alpha': [0.0001, 0.001, 0.01, 0.05, 0.1, \n",
    " 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 2.0, 3.0, \n",
    " 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 20, 50, 100, 500, 1000 ]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef53c9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the relevant libraries\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9657ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying Lasso\n",
    "lasso = Lasso()\n",
    "\n",
    "# cross validation\n",
    "folds = 5\n",
    "model_cv = GridSearchCV(estimator = lasso, \n",
    "                        param_grid = params, \n",
    "                        scoring= 'neg_mean_absolute_error', \n",
    "                        cv = folds, \n",
    "                        return_train_score=True,\n",
    "                        verbose = 1)            \n",
    "\n",
    "model_cv.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece69114",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = pd.DataFrame(model_cv.cv_results_)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eac9551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on grid search best hyper parameters is 0.0001\n",
    "print(model_cv.best_params_)\n",
    "print(model_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febcdb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting mean test and train scoes with alpha \n",
    "cv_results['param_alpha'] = cv_results['param_alpha'].astype('float32')\n",
    "\n",
    "# plotting\n",
    "plt.figure(figsize=(16,5))\n",
    "plt.plot(cv_results['param_alpha'], cv_results['mean_train_score'])\n",
    "plt.plot(cv_results['param_alpha'], cv_results['mean_test_score'])\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('Negative Mean Absolute Error')\n",
    "\n",
    "plt.title(\"Negative Mean Absolute Error and alpha\")\n",
    "plt.legend(['train score', 'test score'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecc21ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#taking alpha of 0.0001 and retraining model\n",
    "alpha = 0.0001\n",
    "\n",
    "lasso = Lasso(alpha=alpha)\n",
    "        \n",
    "lasso.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5a998d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the shortlisted Features and coefficienst in a dataframe\n",
    "\n",
    "lasso_df = pd.DataFrame({'Features':X_train.columns, 'Coefficient':lasso.coef_.round(4)})\n",
    "lasso_df = lasso_df[lasso_df['Coefficient'] != 0.00]\n",
    "lasso_df.reset_index(drop=True, inplace=True)\n",
    "lasso_df.sort_values('Coefficient', ascending=False).head(10).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7198211",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the r2 value for lasso regression. It has score of 92.7% which is good\n",
    "y_train_pred = lasso.predict(X_train)\n",
    "r2_score(y_true=y_train, y_pred=y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c20268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting y_test and y_pred to understand the spread.\n",
    "fig = plt.figure()\n",
    "plt.scatter(y_train,y_train_pred)\n",
    "fig.suptitle('y_train vs y_pred', fontsize=20)              # Plot heading \n",
    "plt.xlabel('y_train', fontsize=18)                          # X-label\n",
    "plt.ylabel('y_pred', fontsize=16)                          # Y-label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240b528d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the residuals. Based on plots the error are normally distributed\n",
    "res=y_train-y_train_pred\n",
    "sns.distplot(res)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8374c4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "#plot the residuals\n",
    "res=y_train-y_train_pred\n",
    "sm.qqplot(res, line ='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa927b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#r2 score on test data\n",
    "y_test_pred=lasso.predict(X_test)\n",
    "r2_score(y_test,y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ab628d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the mean squared error\n",
    "\n",
    "mean_squared_error(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eaace02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the Features and coefficienst in a dataframe\n",
    "lasso_df = pd.DataFrame({'Features':X_train.columns, 'Coefficient':lasso.coef_.round(6)})\n",
    "lasso_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e0f192",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_df.sort_values('Coefficient', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f855290e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the residuals. Plot appears that residuals are normally distributed\n",
    "res=y_test-y_test_pred\n",
    "sns.distplot(res)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a735d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "res=y_test-y_test_pred\n",
    "sm.qqplot(res, line ='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f95db9",
   "metadata": {},
   "source": [
    "### Applying Ridge Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee3e876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying Ridge\n",
    "\n",
    "ridge = Ridge()\n",
    "\n",
    "# cross validation\n",
    "folds = 5\n",
    "#use the grid search to get the lambda value\n",
    "model_cv = GridSearchCV(estimator = ridge, \n",
    "                        param_grid = params, \n",
    "                        scoring= 'neg_mean_absolute_error', \n",
    "                        cv = folds, \n",
    "                        return_train_score=True,\n",
    "                        verbose = 1)            \n",
    "model_cv.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec04f91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cv_results = pd.DataFrame(model_cv.cv_results_)\n",
    "cv_results = cv_results[cv_results['param_alpha']<=1000]\n",
    "cv_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e163f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the best alpha value\n",
    "print(model_cv.best_params_)\n",
    "print(model_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d120a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting mean test and train scoes with alpha \n",
    "cv_results['param_alpha'] = cv_results['param_alpha'].astype('int32')\n",
    "plt.figure(figsize=(16,5))\n",
    "\n",
    "# plotting\n",
    "plt.plot(cv_results['param_alpha'], cv_results['mean_train_score'])\n",
    "plt.plot(cv_results['param_alpha'], cv_results['mean_test_score'])\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('Negative Mean Absolute Error')\n",
    "plt.title(\"Negative Mean Absolute Error and alpha\")\n",
    "plt.legend(['train score', 'test score'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2959f943",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use alpha of 3.0\n",
    "alpha = 3.0\n",
    "ridge = Ridge(alpha=alpha)\n",
    "\n",
    "ridge.fit(X_train, y_train)\n",
    "#get the coefficients\n",
    "ridge.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884ae78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the R2 score for training data. It seems that Ridge is gicving 92.6 R2 score on train set\n",
    "y_train_pred=ridge.predict(X_train)\n",
    "r2_score(y_train,y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf638331",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the R2 score for training data. It seems that Ridge is gicving 88.1 R2 score on test\n",
    "y_test_pred=ridge.predict(X_test)\n",
    "r2_score(y_test,y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7b2b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the mean squared error\n",
    "\n",
    "mean_squared_error(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f6de54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the Features and coefficienst in a dataframe\n",
    "\n",
    "ridge_df = pd.DataFrame({'Features':X_train.columns, 'Coefficient':ridge.coef_.round(6)})\n",
    "ridge_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8601277",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_df.sort_values('Coefficient', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85550518",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the residuals\n",
    "res=y_test-y_test_pred\n",
    "sns.distplot(res)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3ea4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the residuals\n",
    "import statsmodels.api as sm\n",
    "res=y_test-y_test_pred\n",
    "sm.qqplot(res, line ='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8447c0",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Based on 2 models that we have prediced Lasso seems to provide better accuracy.\n",
    "Below are few conclusions of model\n",
    "- lasso works best with alpha of 0.0001\n",
    "- ridge works best with alpha of 3.0\n",
    "- Lasso got higest r2 of 92.7 followed by ridge\n",
    "- Based on Lasso following are the 10 key columns that influence the price of property\n",
    "\n",
    "    GrLivArea\t\n",
    "    OverallCond\t\n",
    "    OverallQual\t\n",
    "    BsmtFinSF1\t\n",
    "    YearBuilt\t\n",
    "    GarageArea\t\n",
    "    BsmtUnfSF\t\n",
    "    LotArea\n",
    "    MSZoning_RL\t\n",
    "    Neighborhood_Crawfor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d59b04d",
   "metadata": {},
   "source": [
    "### Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7889275a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use alpha of 3.0\n",
    "alpha = 3.0*2\n",
    "ridge = Ridge(alpha=alpha)\n",
    "\n",
    "ridge.fit(X_train, y_train)\n",
    "#get the coefficients\n",
    "ridge.coef_\n",
    "\n",
    "#getting the R2 score for training data. It seems that Ridge is gicving 91.9 R2 score on train set\n",
    "y_train_pred=ridge.predict(X_train)\n",
    "r2_score(y_train,y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e3e969",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_df = pd.DataFrame({'Features':X_train.columns, 'Coefficient':ridge.coef_.round(6)})\n",
    "ridge_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ab436e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ridge_df.sort_values('Coefficient', ascending=False).head(10)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222f754c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Features\tCoefficient\n",
    "# 14\tGrLivArea\t0.141488\n",
    "# 11\t1stFlrSF\t0.118750\n",
    "# 3\tOverallQual\t0.113297\n",
    "# 4\tOverallCond\t0.103395\n",
    "# 8\tBsmtFinSF1\t0.084639\n",
    "# 12\t2ndFlrSF\t0.077127\n",
    "# 23\tGarageArea\t0.073562\n",
    "# 10\tBsmtUnfSF\t0.072885\n",
    "# 2\tLotArea\t0.059167\n",
    "# 35\tMSZoning_RL\t0.046331"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1adc7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df86859",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.0001 * 2\n",
    "lasso = Lasso(alpha=alpha)     \n",
    "lasso.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e959153",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = lasso.predict(X_train)\n",
    "r2_score(y_true=y_train, y_pred=y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2deab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_df = pd.DataFrame({'Features':X_train.columns, 'Coefficient':lasso.coef_.round(6)})\n",
    "lasso_df.reset_index(drop=True, inplace=True)\n",
    "lx = lasso_df.sort_values('Coefficient', ascending=False).head(10)\n",
    "lx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad694648",
   "metadata": {},
   "outputs": [],
   "source": [
    "lx.Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c608500c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lasso_df[lasso_df.Coefficient>0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4ff2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ridge_df[ridge_df.Coefficient>0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93837b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train.drop(columns=['GrLivArea','OverallQual','OverallCond','BsmtFinSF1','YearBuilt'], inplace=True)\n",
    "\n",
    "# Applying Lasso\n",
    "lasso = Lasso()\n",
    "\n",
    "# cross validation\n",
    "folds = 5\n",
    "model_cv = GridSearchCV(estimator = lasso, \n",
    "                        param_grid = params, \n",
    "                        scoring= 'neg_mean_absolute_error', \n",
    "                        cv = folds, \n",
    "                        return_train_score=True,\n",
    "                        verbose = 1)            \n",
    "\n",
    "model_cv.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd51438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on grid search best hyper parameters is 0.0001\n",
    "print(model_cv.best_params_)\n",
    "print(model_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4c658b",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.0001\n",
    "lasso = Lasso(alpha=alpha)     \n",
    "lasso.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398732b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = lasso.predict(X_train)\n",
    "r2_score(y_true=y_train, y_pred=y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99796296",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_df = pd.DataFrame({'Features':X_train.columns, 'Coefficient':lasso.coef_.round(6)})\n",
    "lasso_df.reset_index(drop=True, inplace=True)\n",
    "lasso_df.sort_values('Coefficient', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc89a66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14\tGrLivArea\t0.353744\n",
    "# 4\tOverallCond\t0.141184\n",
    "# 3\tOverallQual\t0.137697\n",
    "# 8\tBsmtFinSF1\t0.100313\n",
    "# 5\tYearBuilt\t0.087424\n",
    "# 23\tGarageArea\t0.081067\n",
    "# 10\tBsmtUnfSF\t0.080736\n",
    "# 2\tLotArea\t0.059988\n",
    "# 35\tMSZoning_RL\t0.054618\n",
    "# 58\tNeighborhood_Crawfor\t0.050446"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4178873",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7df4f2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
